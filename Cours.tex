%%%%%%%%%%%%%
% Préambule %
%%%%%%%%%%%%%

\documentclass[12pt,a4paper,oneside,fleqn]{book} % Utiliser article si nécessaire
\usepackage[latin1]{inputenc} % Pour les accents
\usepackage[T1]{fontenc} 
\usepackage[francais]{babel} % Pour la typographie
\usepackage[usenames]{color} % Pour les couleurs
\usepackage{amssymb} % Pour les symboles
\usepackage{amsmath} % Pour les maths
\usepackage{amsthm} % Pour les théorèmes
\usepackage{fullpage} % Pour les marges
\usepackage{setspace} % Pour les espaces
\usepackage{array} % Pour les tableaux
\usepackage{tikz} % Pour les graphes
\usepackage{pgfplots} % Pour les fonctions

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{1}
\renewcommand\thesection{\Roman{section}}
\renewcommand\thesubsection{\quad\arabic{subsection}}
\renewcommand\thesubsubsection{\qquad\alph{subsubsection}}
\newtheorem{example}{Exemple}
\newtheorem{remark}{Remarque}

% Commandes ponctuelles

\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\diff}[1]{\,\mathrm{d}#1}
\renewcommand{\L}[1]{\mathcal{L}\left\{#1\right\}}
\newcommand{\Z}[1]{\mathcal{Z}\left\{#1\right\}}
\newcommand{\Li}[1]{\mathcal{L}^{-1}\left\{#1\right\}}
\newcommand{\Zi}[1]{\mathcal{Z}^{-1}\left\{#1\right\}}
\onehalfspacing
\onehalfspacing

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}

\title{Deuxième année --- Méthodes mathématiques}
\author{Richard \textsc{Degenne}, L3-B}
\date{\today}


\maketitle

\pagebreak

\tableofcontents

\pagebreak

\chapter{Intégrales générales, ou impropres}

\section{Définition}

Soit $I\subset\R$ un intervalle dont les extrémités $a<b$ (pouvant être $\pm\infty$) sont exclues et $f:I\to\R$ une fonction continue par morceaux sur $I$. Pour chaque intervalle $[x;y]\in I$, l'intégrale $\int_x^y f(t)\diff{t}$ est bien définie.

Si, pour $x$ tendant vers $a$ et $y$ tendant vers $b$, l'intégrale admet une limite finie, alors on dit que l'intégrale impropre $\int_a^b f(t)\diff{t}$ est convergente, et, par définition,
\[\int_a^b f(t)\diff{t}=\lim_{x\to a,y\to b}\int_x^y f(t)\diff{t}\]

Si la limite est infinie ou s'il n'y a pas de limite, on dit que l'intégrale impropre est divergente.

\subsection{Relation de Chasles}

Pour $c\in I$, on a
\[\int_x^y f(t)\diff{t} = \int_x^c f(t)\diff{t} \int_c^y f(t)\diff{t}\]

Si une intégrale impropre converge, alors toute relation de Chasles formé à partir de cette intégrale converge également. En prenant le cas particulier $c=a$, on peut en déduire que
\[\int_a^b f(t)\diff{t}\text{ converge}\begin{array}{l}\iff\lim_{y\to b}\int_a^y f(t)\diff{t}\text{ existe et est fini.}\\\iff\lim_{x\to a}\int_x^b f(t)\diff{t}\text{ existe et est fini.}\end{array}\]

\section{Exemples}

\begin{example}
	\begin{align*}
		\int_1^x\frac{1}{t^2}\diff{t} & = \left[-\frac{1}{t}\right]_1^x\\
		                              & = 1-\frac{1}{x}\\
	\end{align*}
\end{example}

\begin{example}
	\begin{align*}
		\int_1^\infty\frac{1}{t^2}\diff{t} & = \lim_{x\to+\infty}\int_1^x\frac{1}{t^2}\diff{t}\\
		                                   & = \lim_{x\to+\infty}1-\frac{1}{x}\\
		                                   & = 1
	\end{align*}
\end{example}

\begin{example}
	\begin{align*}
		\int_1^\infty\frac{1}{t}\diff{t} & = \lim_{x\to+\infty}\int_1^x\frac{1}{t}\diff{t}\\
		                                 & = \lim_{x\to+\infty}1-\ln(x)\\
		                                 & = +\infty
	\end{align*}
\end{example}

\begin{example}
	\begin{align*}
		\int_0^x\cos(t)\diff{t} & = [\sin(t)]_{0}^{x}\\
		                        & = \sin(x)
	\end{align*}

	Or, $\lim_{x\to\infty}\sin(x)$ n'existe pas. Donc, $\int_0^x \cos(t)\diff{t}$ diverge.
\end{example}

\begin{example}
	\begin{align*}
		\int_0^\infty e^{-t}\diff{t} & = \lim_{x\to\infty}\int_0^x e^{-t}\diff{t}\\
		                             & = \lim_{x\to\infty}[-e^{-t}]_0^x\\
					     & = \lim_{x\to\infty}1-e^{-x}\\
					     & = 1
	\end{align*}
\end{example}

\begin{example}
	\begin{align*}
		\int_0^1 \frac{1}{\sqrt{t}}\diff{t} & = \lim_{x\to 0}\int_x^1 \frac{1}{\sqrt{t}}\diff{t}\\
		                                    & = \lim_{x\to 0}\left[2\sqrt{t}\right]_x^1\\
					            & = 2
	\end{align*}
\end{example}

\section{Propriétés}

Si $a$ et $b$ sont des valeurs finies et si $f$ est une fonction continue dans l'un des intervalles $[a;b[$, $]a;b]$ ou $]a;b[$ qui se prolonge par continuité à $[a;b]$, alors $\int_a^b f(t)\diff{t}$ converge.

\begin{example}
\[\int_0^1\frac{\sin(t)}{t}\diff{t}\]
est convergente.\footnote{\emph{cf.} le développement limité de $\sin(t)$ au voisinage de $t$.}
\end{example}

Évidemment, les résultats et propriétés valables pour les intégrales classiques (changements de variable, intégration par parties, linéarité,\ldots) restent valables pour les intégrales impropres.

\section{Intégrale absolument convergente}

Soit $I$ un intervalle d'extrémités $a$ et $b$ appartenant à $\bar\R = \R\backslash\pm\infty$. Soit $f:I\to\R$ une fonction continue par morceaux et $g:I\to\R^+$ telle que $\forall t\in I,\lvert f(t)\rvert \le g(t)$. On a alors
\[\int_a^b g(t)\diff{t}\text{ converge}\implies \int_a^b f(t)\diff{t}\text{ converge}\]

Ainsi, on dit que $\int_a^b f(t)\diff{t}$ est absolument convergente si $\int_a^b\lvert f(t)\rvert\diff{t}$ converge. Toute intégrale imporpre absolument convergente est convergente.

\begin{remark}
	La réciproque est généralement fausse. Par exemple, $\int_0^\infty\frac{\sin(t)}{t}\diff{t}$ converge, mais $\int_0^\infty\left\lvert\frac{\sin(t)}{t}\right\rvert\diff{t}$ diverge.
\end{remark}

\chapter{Séries numériques}

\section{Convergence d'une série de nombres complexes}

\subsection{Définitions}

Soit $(u_n)$ une suite de nombres complexes. On appelle \emph{somme partielle} d'indice $n$ le nombre $S_n=\sum_{k=0}^n u_k = u_0+u_1+\dotsb+u_n$. On dit que la série de terme général $u_n$ converge lorsque la suite $(S_n)$ converge, autrement dit quand $\lim_{n\to\infty}\sum_{k=0}^n u_k$ existe et est finie.

On dit que $\lim_{n\to\infty} S_n$ est la somme de la série de terme général $u_n$ et on note $\sum_0^\infty u_n$.

\begin{example}
	\begin{align*}
		\sum_{n=1}^\infty \frac{1}{n(n+1)} & = \lim_{n\to\infty}\sum_{k=1}^{n}\frac{1}{k(k+1)}\\
			                           & = \lim_{n\to\infty}\sum_{k=1}^{n}\left(\frac{1}{n}-\frac{1}{n+1}\right)\\
						   & = \lim_{n\to\infty}1 - \frac{1}{n+1} \qquad\text{(La somme se téléscope.)}\\
						   & = 1
	\end{align*}

	On dit que la série de terme général $\frac{1}{n(n+1)}$ converge et que sa somme vaut 1.
\end{example}

\subsection{Condition nécessaire de convergence}

Si la série de terme général $u_n$ converge vers $l$, autrement dit si la somme partielle $S_n$ vérifie $\lim_{n\to\infty} S_n = l$, alors il est nécessaire que 
\[\lim_{n\to\infty} S_n - S_{n-1} =  \lim_{n\to\infty} u_n = 0\]

Si on prend $q\in\C$, la série géométrique de terme général $q^n$ converge dans $\C$ si, et seulement si, $\vert q\vert < 1$. À ce moment-là, $\sum_0^\infty=\frac{1}{1-q}$.

\begin{example}
	\begin{align*}
		\sum_0^\infty\left(\frac{1}{2}\right)^n & = \frac{1}{1-\frac{1}{2}}\\
			                                & = 2
	\end{align*}
\end{example}

Soient $u_n$ et $v_n$ les termes généraux de deux séries convergentes. Pour tout $\lambda,\mu\in\C$, on a
\[\sum_{n=0}^\infty\lambda\,u_n + \mu\,v_n = \lambda\sum_{n=0}^\infty u_n + \mu\sum_{n=0}^\infty v_n\]

On en déduit alors que la série de terme général $\lambda\,u_n + \mu\,v_n$ converge également.

\section{Séries à termes réels positifs}

\subsection{Condition nécessaire et suffisante de convergence}

Soit $(u_n)$ une suite de nombres réels positifs. La série de terme général $u_n$ converge si, et seulement si,
\[\exists M>0\mid\forall n\in\N,\sum_{k=0}^n u_k < M \iff \sum{k=0}^\infty u_k < +\infty\]

En effet, la suite composée des sommes partielles d'une suite à termes positifs est croissante. Dans la mesure où toute suite croissante majorée converge, on peut affirmer que si la suite des sommes partielles est majorée, alors elle converge vers $\sup\left(\left\{\sum_{k=0}^n u_k,n\in\N\right\}\right)$.

\subsection{Critère de comparaison}

Soient $u_n$ et $v_n$ les termes généraux de deux séries à termes positifs tels que, pour tout $n\in\N$, on ait $0<u_n<v_n$.

Si $\sum_{n=0}^\infty v_n$ converge, alors $\sum_{n=0}^\infty u_n$ converge également et $\sum_{n=0}^\infty u_n\le\sum_{n=0}^\infty v_n$.

Inversement, si $\sum{n=0}^\infty u_n$ diverge, alors $\sum_{n=0}^\infty v_n$ diverge également.

\begin{example}

$\sum_{n=0}^{\infty}\frac{1}{n^2\sqrt{n}}$ converge car on a $\frac{1}{n^2\sqrt{n}}\le\frac{1}{n^2}$, qui est convergente.
\end{example}

\begin{example}

$\sum_{n=0}^\infty\frac{1}{\sqrt{n}}$ diverge car on a $\frac{1}{\sqrt{n}}\ge\frac{1}{n}$, qui diverge.
\end{example}

\subsection{Critère d'Alembert}

Soit $(u_n)$ une suite de réels positifs telle que $\lim_{n\to\infty} \frac{u_{n+1}}{u_n} = q$.

\begin{itemize}
	\item{Si $q<1$, alors la série converge ;}
	\item{Si $q>1$, alors la série diverge ;}
	\item{Si $q=1$, on ne peut pas se prononcer.}
\end{itemize}

\begin{example}
	\begin{align*}
		u_n                                  & = \frac{n}{2^n}\\
		\lim_{n\to\infty}\frac{u_{n+1}}{u_n} & = \lim_{n\to\infty}\frac{n+1}{2^{n+1}}\times\frac{2^n}{n}\\
		                                     & = \lim_{n\to\infty}\frac{1}{2}\times\frac{n+1}{n}\\
						     & = \frac{1}{2}
	\end{align*}

	On a $q<1$, donc la série de terme général $\frac{n}{2^n}$ converge.
\end{example}

\begin{example}
	\begin{align*}
		u_n                                  & = \frac{2^n}{2!}\\
		\lim_{n\to\infty}\frac{u_{n+1}}{u_n} & = \lim_{n\to\infty}\frac{2^{n+1}}{(n+1)!}\times\frac{n!}{2^n}\\
		                                     & = \lim_{n\to\infty}\frac{2}{n+1}\\
						     & = 0
	\end{align*}

	On a $q<1$, donc la série de terme général $\frac{2^n}{n!}$ converge.
\end{example}

\subsection{Comparaison d'une série et d'une intégrale}

Soit $f:[1;+\infty]\to\R^+$ une fonction continue et décroissante. On a alors l'équivalences suivante,
\[\sum_{n=0}^\infty f(n)\text{ converge} \iff \int_1^\infty f(t)\diff{t}\text{ converge}\]

Un corollaire de ce théorème est que la série de terme général $\frac{1}{n^\alpha}$ converge si, et seulement si, $\alpha>1$.

\section{Séries absolument convergentes}

Soit $(u_n)_{n\in\N}$ une suite de nombres complexes. Une série est dite absolument convergente si $\sum_{n=0}^\infty\vert u_n\vert$ converge. De plus, on en peut en déduire que $\sum_{n=0}^\infty u_n$ converge également, mais la réciproque est généralement fausse.

\begin{remark}[Cas des séries alternées]
	Soit $(u_n)$ une suite de nombres réels alternativement positifs et négatifs. Si la suite $(\vert u_n\vert)$ est décroissante et si $\lim_{n\to\infty} \vert u_n\vert = 0$, alors $\sum_{n=0}^\infty$ est convergente.
\end{remark}

\chapter{Transformée de Laplace}

\section{Intégrale de Laplace}

\subsection{Définition}

Soit $f$ une fonction définie sur $\R$ et supposée nulle pour tout $t<0$.\footnote{On parle alors de fonction causale.} On appelle transformée de Laplace de $f$ la fonction $F$ définie par
\[F(p) = \int_0^\infty e^{-pt}f(t)\diff{t}\]
où $p$ est une variable complexe.

On écrit $F(p) = \L{f(t)}$, ou bien $f(t)\xrightarrow{\mathcal{L}}F(p)$. On dit que $F(p)$ est l'image de $f(t)$ et que $f(t)$ est l'originial de $F(p)$.

\begin{remark}
$F(p)$ est bien à valeur dans $\C$ bien que $f(t)$ soit à valeurs dans $\R$.
\end{remark}

\subsection{Conditions d'existence}

La transformée de Laplace d'une fonction $f(t)$ n'existe que si $\int_0^\infty e^{-pt}f(t)\diff{t}$ converge. On est alors amené à définir deux conditions sur $f$ pour s'assurer de l'existence de sa transformée de Laplace :

\begin{itemize}
	\item{Elle doit être continue par morceau sur tout intervalle $[0;t_0]$ de $\R$ ;}
	\item{Elle doit être d'ordre exponentiel à l'infini, c'est-à-dire respecter la relation suivante
		\[\exists M>0,\alpha\in\R\mid\vert f(t)\vert<M\,e^{\alpha\,t}\]
	}
\end{itemize}

\section{Transformée de Laplace des fonctions usuelles}

\subsection{Échelon unité}

L'échelon unité est la fonction $\Gamma$ définie sur $\R$ comme suit,
\[\Gamma(t) = \left\{
	\begin{array}{l}
		0\quad\forall t<0\\
		1\quad\forall t\ge 0
	\end{array}\right.\]
\begin{figure}[h]
	\begin{center}
	\begin{tikzpicture}
		\draw[->] (-4.1,0) -- (4.1,0)
			node[anchor=north]{$t$};
		\draw[->] (0,-0.1) -- (0,3.1)
			node[anchor=west]{$\Gamma(t)$};
		\draw[red,thick] (-4,0) -- (0,0) -- (0,2)
			node[black,anchor=east]{$1$} -- (4,2);
	\end{tikzpicture}
	\end{center}
	\caption{Échelon unité}
\end{figure}

\begin{align*}
	\L{\Gamma(t)} & = \int_0^\infty e^{-pt} \times 1\diff{t}\\
		      & = \lim_{T\to\infty}\left[-\frac{e^{-pt}}{p}\right]_0^T\\
		      & = \lim_{T\to\infty}\vert e^{-pt}\vert\\
		      & = \lim_{T\to\infty}\left\lvert e^{\Re(p)t}\right\rvert\\
		      & = 0\\
\end{align*}

Donc, $\L{\Gamma(t)}$ existe et $\L{\Gamma(t)} = \frac{1}{p}$.

\subsection{Impulsion de Dirac}

\begin{figure}[h!]
	\begin{center}
	\begin{tikzpicture}
		\draw[->] (-4.1,0) -- (4.1,0)
			node[anchor=north]{$t$};
		\draw[->] (0,-0.1) -- (0,3.1)
			node[anchor=west]{$\delta(t)$};
		\draw[red,thick] (-4,0) -- (0,0) -- (0,2)
			node[black,anchor=east]{$\frac{1}{\varepsilon}$} -- (0.5,2) -- (0.5,0)
			node[black,anchor=north]{$\varepsilon$} -- (4,0);
	\end{tikzpicture}
	\end{center}
	\caption{Fonction créneau}
\end{figure}

\begin{remark}
	\[\forall\varepsilon>0,\int_{-\infty}^{+\infty}\delta_\varepsilon(t) = 1\]
\end{remark}

La famille de fonction des $\delta_\varepsilon$ est appelée créneau. Cependant, lorsque $\varepsilon$ tend vers $0$, on parle d'impulsion de Dirac, notée $\delta$, et sert à représenter en physique des évènements on des actions ayant lieu sur un temps très court. On écirt d'ailleurs abusivement
\[\delta(t) = \left\{\begin{array}{l}
	0\quad\forall t\ne 0\\
	\infty\quad\text{pour }t=0\end{array}\right.\]

\begin{align*}
	\L{\delta_\varepsilon}                                 & = \int_0^\infty\delta_\varepsilon(t)\,e^{-pt}\diff{t}\\
	                                                       & = \int_0^\varepsilon\frac{1}{\varepsilon}\,e^{-pt}\diff{t}\\
			                                       & = \frac{1}{\varepsilon}\int_0^\varepsilon e^{-pt}\diff{t}\\
			                                       & = \frac{1-e^{-pt}}{p\,\varepsilon}\\
	\lim_{\varepsilon\to 0}\frac{1-e^{-pt}}{p\,\varepsilon} & = 1
\end{align*}

Donc, $\L{\delta(t)}$ existe et $\L{\delta(t)} = 1$.

\subsection{Fonction puissance}

Soit un entier naturel $n$. On pose alors $f(t) = t^n\,\Gamma(t)$.

\begin{align*}
	\L{t^n} & = \int_0^\infty t^n\,e^{-pt}\diff{t}\\
		& = \left[-\frac{e^{-pt}}{p}t^n\right]_0^\infty + \int_0^\infty\frac{n}{p}t^{n-1}\,e^{-pt}\diff{t}\\
		& = 0 + \frac{n}{p}\int_0^{n-1}\,e^{-pt}\diff{t}\\
	        & = \frac{n!}{p^n}\int_0^\infty 1\times e^{-pt}\diff(t) \qquad(\text{On intègre par parties $n$ fois.})\\
	        & = \frac{n!}{p^n}\left[-\frac{e^{-pt}}{p}\right]_0^\infty
\end{align*}

Donc, $\L{t^n}$ existe et $\L{t^n} = \frac{n!}{p^{n+1}}$.

\subsection{Fonction exponentielle}

On pose ici $\alpha\in\R$ et $f(t) = e^{-\alpha t}\,\Gamma(t)$.

\begin{align*}
	\L{e^{-\alpha t}} & = \int_0^\infty e^{-\alpha t}e^{-pt}\diff{t}\\
		          & = \int_0^\infty e^{-t(p+\alpha)}\diff{t}\\
	                  & = \left[-\frac{e^{-t(p+\alpha)}}{p+\alpha}\right]_0^\infty
\end{align*}

Donc, $\L{e^{-\alpha t}}$ existe et vaut $\frac{1}{p+\alpha}$.

\subsection{Fonctions trigonométriques}

\subsubsection{Sinus}

On pose $f(t) = \sin(\omega t)\,\Gamma(t)$.

\begin{align*}
	\L{\sin(\omega t)} & = \L{\frac{1}{2j}(e^{-j\omega t}-e^{j\omega t})}\\
	                   & = \frac{1}{2j}\left(\L{e^{-j\omega t}}-\L{e^{j\omega t}}\right)\\
			   & = \frac{1}{2j}\left(\frac{1}{p-j\omega} - \frac{1}{p+j\omega}\right)\\
			   & = \frac{\omega}{p^2+\omega^2}\\
\end{align*}

\subsubsection{Cosinus}

On pose $f(t) = \cos(\omega t)\,\Gamma(t)$.

\begin{align*}
	\L{\cos(\omega t)} & = \L{\frac{1}{2}(e^{-j\omega t}+e^{j\omega t})}\\
	                   & = \frac{1}{2}\left(\L{e^{-j\omega t}} + \L{e^{j\omega t}}\right)\\
			   & = \frac{1}{2}\left(\frac{1}{p+j\omega} + \frac{1}{p-j\omega}\right)\\
			   & = \frac{p}{p^2+\omega^2}
\end{align*}

\section{Propriétés}

\subsection{Linéarité}

\[\L{a\,f(t)+b\,g(t)}=a\,\L{f(t)}+b\,\L{g(t)}\]

\subsection{Multiplication par un scalaire}

Soit $\alpha\in\R$ et $f(t)$ telle que $\L{f(t)} = F(p)$.

\[\L{f(\alpha t)}  = \frac{1}{\alpha}F\left(\frac{p}{a}\right)\]

\subsection{Retard}

\begin{figure}[h!]
	\begin{center}
	\begin{tikzpicture}
		\draw[->] (-1.1,0) -- (4.1,0)
			node[anchor=north]{$t$};
		\draw[->] (0,-0.1) -- (0,3.1)
			node[anchor=west]{$f(t)$};
		\draw[red,thick] (-1,0) -- (0,0) -- (0,1) sin (2,2)
			node[anchor=south]{$f(t)$};
		\draw[blue](-1,0) -- (1,0)
			node[black,anchor=north]{$\alpha$} -- (1,1) sin (3,2)
			node[anchor=west]{$f(t-\alpha)$};
	\end{tikzpicture}
	\end{center}
	\caption{Fonction retardée}
\end{figure}

Soit $\alpha\in\R^+$.

\begin{align*}
	\L{f(t-\alpha)} & = \int_\alpha^\infty f(t-\alpha)\,e^{-pt}\diff{t}\\
	                & = \int_0^\infty f(x)\,e^{-p(x+\alpha)}\diff{x}\qquad(\text{On pose $x=t-\alpha$})\\
		        & = e^{-pa}\int_0^\infty f(x)\,e^{-px}\diff{x}\\
		        & = e^{-pa}\L{f(t)}
\end{align*}

\begin{example}[Les fonctions périodiques]
	Soit $f(t)$ une fonction de période $T$. On va ici décomposer la fonction sur chaque période. On définit $f_0(t)=f(t)\forall t\in[0;T] ; 0\forall t\geq T$.
	\begin{figure}[h!]
	\begin{center}
		\begin{tikzpicture}
			\draw[->] (-0.1,0) -- (10,0) node[anchor=north west]{$t$};
			\draw[->] (0,-0.1) -- (0,4);
			\draw (4,2pt) -- (4,-2pt) node[anchor=north]{$T$};
			\draw (8,2pt) -- (8,-2pt) node[anchor=north]{$2T$};

			\draw[red, very thick] (0,2) sin (1,3) cos (2,2) sin (3,1) cos (4,2) sin (5,3) cos (6,2) sin (7,1) cos (8,2) sin (9,3) node[anchor=west,red]{$f(t)$};
			\draw[blue] (0,2) sin (1,3) cos (2,2) sin (3,1) cos (4,2) -- (4,0) -- (9,0) node[anchor=south west]{$f_0(t)$};
		\end{tikzpicture}
	\end{center}
	\caption{Décomposition d'une fonction périodique}
	\end{figure}
	\begin{align*}
		\L{f(t)} & = \L{f_0(t)  +f_0(t-T)      +f_0(t-2T)+\dotsb}\\
		         & = \L{f_0(t)} +\L{f_0(t-T)}  +\L{f_0(t-2T)}+\dotsb\\
			 & = F_0(p)     +e^{-pT}F_0(p) +e^{-2pT}F_0(p)+\dotsb\\
			 & = (1+e^{-pT}+e^{-2pT}+\dotsb)F_0(p)\\
			 & = \frac{1}{1-e^{-pT}}F_0(p)\\
	\end{align*}
	Pour les fonctions périodiques usuelles, il faut plutôt utiliser une table de transformée plutôt que cette méthode.
\end{example}

\subsection{Dérivation}

Soit $f:\R^+\to\R$ une fonction continue par morceaux sur tout intervalle fermé $[0;t_0\subset\R^+$.

\begin{align*}
	\L{\dot{f}(t)} & = \int_0^\infty\dot{f}(t)\,e^{-pt}\diff{t}\\
	               & = \left[e^{-pt}f(t)\right]_0^\infty + \int_0^\infty p\times f(t)\,e^{-pt}\diff{t}\\
\end{align*}

Or, par définition, $\lim_{x\to\infty} f(t)\,e^{-pt} = 0$, ce qui implique que $[f(t)\,e^{-pt}]_0^\infty = -f(0^+)$.

Donc,
\[\L{\dot{f}(t)\,\Gamma(t)} = p\L{f(t)}-f(0^+)\]

De manière générale, on a
\[\L{f^{(n)}(t)} = p^n\L{f(t)} - p^{n-1}f(0^+) - p^{n-2}\dot{f}(0^+) - \dotsb - p\times f^{(n-1)}(0^+)\]

\subsection{Primitivation}

Soit $\varphi(t) = \int_0^\infty f(x)\diff{x}$ (c'est-à-dire $\dot{\varphi}(t) = f(t)$) et $\varphi(0^+) = 0$.

On peut alors écrire $\L{\dot{\varphi}(t)} = p\L{\varphi(t)}$.

Or, $\dot{\varphi}(t) = f(t)$, d'où
\[\L{\varphi(t)} = \frac{\L{f(t)}}{p}\]

\subsection{Théorèmes des valeurs initiale et finale}

On peut déterminer le comportement asymptotique d'une fonction $f(t)$ en ne connaissant que sa transformée.

\begin{align*}
	\lim_{p\to\infty}p\L{f(t)} & = f(0^+)\\
	\lim_{p\to 0}p\L{f(t)}     & = f(\infty)\\
\end{align*}

\chapter{Produit de convolution}

\section{Définition}

Lorsqu'il existe, on appelle produit de convolution de deux fonctions $f$ et $g$ la fonction $h$ définie par
\[\int_{-\infty}^{+\infty}f(t-x)g(x)\diff{x}\]

\begin{remark} On note $h=f*g$ et on lit \emph{"le produit de convolution de $f$ par $g$"} ou \emph{"$f$ étoile $g$"}.\end{remark}

\section{Propriétés}

\subsection{Commutativité}

Le produit de convolution est commutatif, c'est-à-dire que
\[f*g=g*f\]

\subsection{Associativité}

Le produit de convolution est associatif, c'est-à-dire que
\[f*(g*h) = (f*g)*h\]

\subsection{Distributivité}

Le produit de convolution est distributif, c'est-à-dire que 
\[f*(g+h) = f*g\ +\ f*h\]

\section{Produit de convolution et impulsion de Dirac}

On rappelle que l'impulsion de Dirac est la fonction notée $\delta(t)$ définie par un créneau de largeur $\varepsilon\to0$ et d'amplitude $\frac{1}{\varepsilon}\to\infty$ avec $ \varepsilon>0$ telle que $\int_{-\infty}^{+\infty}\delta(t)\diff{t} = 1$.

Soit $f$ une fonction continue sur $\R$.

\begin{align*}
	\int_{-\infty}^{+\infty}\delta(t)\,f(t)\diff{t} & = \int_0^{\varepsilon}\frac{1}{\varepsilon}f(t)\diff{t}\\
		                                        & = \frac{1}{\varepsilon}\int_0^{\varepsilon}f(t)\diff{t}\\
\end{align*}

Ainsi, on peut dire que
\[\lim_{\varepsilon\to 0}\delta(t)\,f(t) = f(0)\]
d'où
\[\int_{-\infty}^{+\infty}\delta(t)\,f(t)\diff{t} = 0\]

Par conséquence, $f*\delta=f$. L'impulsion de Dirac est l'élément neutre du produit de convolution. On peut également définir une $g$ comme l'inverse de $f$ pour le produit de convolution si $f*g=\delta$.

\begin{remark}
	\[f(t)*\delta(t-t_0) = \int_{-\infty}^{+\infty}f(x)\,\delta\big(x-(t-t_0)\big)\diff{x} = f(t-t_0)\]
\end{remark}

\section{Applications à la physique}

On va décrire un système physique au moyen d'un opérateur liant un signal d'entrée à un signal de sortie. On cherche à établir l'expression mathématique de cet opérateur.

On dit qu'un système est continu lorsque l'on peut trouver une équation instantanée ou différentielle avec le temps comme variable indépendante donnant la relation entre les signaux d'entrée et de sortie.

\subsection{Système linéaire}

Soit $y(t)$ la réponse du système à un signal d'entrée $x(t)$. Le système est dit linéaire si la réponse du système à $\lambda\,x(t)$ est $\lambda\,y(t)$, où $\lambda$ désigne un réel.

\begin{figure}[h!]
\begin{center}
	\begin{tikzpicture}
		\draw (0,0) -- node[above]{$x(t)$} (1,0);
		\draw (1,-0.75) rectangle (4,0.75);
		\draw (4,0) -- node[above]{$y(t)$} (5,0);
		% TODO Draw an arrow for implication here
		\begin{scope}[xshift=8cm]
			\draw (0,0) -- node[above]{$\lambda\,x(t)$} (1,0);
			\draw (1,-0.75) rectangle (4,0.75);
			\draw (4,0) -- node[above]{$\lambda\,y(t)$} (5,0);
		\end{scope}
	\end{tikzpicture}
\end{center}
\caption{Système linéaire}
\end{figure}

\subsection{Système invariant}

Un système est invariant dans le temps lorsqu'une translation dans le temps de l'entrée $x(t-\tau)$ se traduit par la même translation en sortie du système $y(t-\tau)$.

\begin{figure}[h!]
\begin{center}
	\begin{tikzpicture}
		\draw (0,0) -- node[above]{$x(t)$} (1,0);
		\draw (1,-0.75) rectangle (4,0.75);
		\draw (4,0) -- node[above]{$y(t)$} (5,0);
		% TODO Draw an arrow for implication here
		\begin{scope}[xshift=8cm]
			\draw (0,0) -- node[above]{$x(t-\tau)$} (1,0);
			\draw (1,-0.75) rectangle (4,0.75);
			\draw (4,0) -- node[above]{$y(t-\tau)$} (5,0);
		\end{scope}
	\end{tikzpicture}
\end{center}
\caption{Système invariant}
\end{figure}
\subsection{Système causal}

En physique, l'effet ne peut précéder la cause. Un système continu est causal si $y(t_0)$ est indépendant de $x(t_1)$, avec $t_1$ postérieur à $t_0$.

De la même manière, on dire que le système est stable si, pour tout signal d'entrée fini, le signal de sortie est fini.

\subsection{Réponse impulsionnelle}

On appelle réponse impulsionnelle d'un système le signal de sortie $h(t)$ obtenu lorsque le signal d'entrée est une impulsion de Dirac.

\begin{figure}[h!]
\begin{center}
	\begin{tikzpicture}
		\draw (0,0) -- node[above]{$\delta(t)$} (1,0);
		\draw (1,-0.75) rectangle (4,0.75);
		\draw (4,0) -- node[above]{$h(t)$} (5,0);
	\end{tikzpicture}
\end{center}
\caption{Réponse impulsionnelle}
\end{figure}

\subsection{Réponse du système à une entrée quelconque}

Un système continu linéaire invariant peut être entièrement décrit par sa réponse impulsionnelle. La connaise de $h(t)$ permet de calculer le signal de sortie correspondant à n'importe quel signal d'entrée $x(t)$.

\[y(t) = \int_{-\infty}^{+\infty} x(\tau)\,h(t-\tau)\diff{\tau} = x*h\]

\subsection{Produit de convolution de fonctions causales}

Soient $f$ et $g$ deux fonctions causales.

\begin{align*}
	(f*g)(t) & = \int_{-\infty}^{+\infty}f(t)\,\Gamma(t)\times g(t-\tau)\,\Gamma(t-\tau)\diff{\tau}\\
		 & = \int_0^t f(t)\,g(t-\tau)\diff{\tau}
\end{align*}

\end{document}
